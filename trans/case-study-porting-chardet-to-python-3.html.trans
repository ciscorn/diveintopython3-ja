en:<title>Case study: porting chardet to Python 3 - Dive Into Python 3</title>
ja:<title>ケーススタディ: chardetをPython 3に移植する - Dive Into Python 3 日本語版</title>


en:<p>You are here: <a href=index.html>Home</a> <span class=u>&#8227;</span> <a href=table-of-contents.html#case-study-porting-chardet-to-python-3>Dive Into Python 3</a> <span class=u>&#8227;</span>
ja:<p>現在地: <a href=index.html>ホーム</a> <span class=u>&#8227;</span> <a href=table-of-contents.html#case-study-porting-chardet-to-python-3>Dive Into Python 3</a> <span class=u>&#8227;</span>


en:<h1>Case Study: Porting <code>chardet</code> to Python 3</h1>
ja:<h1>ケーススタディ: <code>chardet</code>をPython 3に移植する</h1>


en:<p><span class=u>&#x275D;</span> Words, words. They&#8217;re all we have to go on. <span class=u>&#x275E;</span><br>&mdash; <a href=http://www.imdb.com/title/tt0100519/quotes>Rosencrantz and Guildenstern are Dead</a>
ja:<p><span class=u>&#x275D;</span> 言葉だよ言葉。俺たちはこいつらを口に出してりゃいいんだ。<span class=u>&#x275E;</span><br>&mdash; <a href=http://www.imdb.com/title/tt0100519/quotes>Rosencrantz and Guildenstern are Dead</a>


en:<p class=f>Question: what&#8217;s the #1 cause of gibberish text on the web, in your inbox, and across every computer system ever written? It&#8217;s character encoding. In the <a href=strings.html>Strings</a> chapter, I talked about the history of character encoding and the creation of Unicode, the &#8220;one encoding to rule them all.&#8221; I&#8217;d love it if I never had to see a gibberish character on a web page again, because all authoring systems stored accurate encoding information, all transfer protocols were Unicode-aware, and every system that handled text maintained perfect fidelity when converting between encodings.
ja:<p class=f>問題: ウェブ、メール、そして今までに作られたありとあらゆるコンピュータシステムにおける、文字化けの原因ナンバーワンは何でしょう？ 答えは文字コードだ。<a href=strings.html>文字列の章</a>では、文字コードの歴史と、「すべてを支配する1つの文字コード」であるUnicodeの誕生について話した。しウェブページ上で二度と文字化けを見ずに済むようになるなら、私はUnicodeを愛すのだろうけれど、それには、すべてのオーサリングシステムが正確な文字コード情報を格納し、すべての転送プロトコルがUnicodeに対応し、テキストを扱うすべてのシステムが文字コードの変換時に完全な忠実さを持つ必要がある。


en:<p>I&#8217;d also like a pony.
ja:<p>私はポニーも欲しいんだ。


en:<p>A Unicode pony.
ja:<p>ユニコードのポニー。


en:<p>A Unipony, as it were.
ja:<p>言ってみれば、ユニポニー。


en:<p>I&#8217;ll settle for character encoding auto-detection.
ja:<p>私は文字コードの自動検出で我慢しておくよ。


en:<h2 id=faq.what>What is Character Encoding Auto-Detection?</h2>
ja:<h2 id=faq.what>文字コードの自動検出とは何か？</h2>


en:<p>It means taking a sequence of bytes in an unknown character encoding, and attempting to determine the encoding so you can read the text. It&#8217;s like cracking a code when you don&#8217;t have the decryption key.
ja:<p>要するに、どの文字コードで符号化されたのか分からないバイト列を受け取って、その文字コードを推測することでテキストを読み込めるようにしようというわけだ。これは、復号鍵を知らない状態で暗号を解読しようとするのに似ている。


en:<h3 id=faq.impossible>Isn&#8217;t That Impossible?</h3>
ja:<h3 id=faq.impossible>それって不可能じゃないの？</h3>


en:<p>In general, yes. However, some encodings are optimized for specific languages, and languages are not random. Some character sequences pop up all the time, while other sequences make no sense. A person fluent in English who opens a newspaper and finds &#8220;txzqJv 2!dasd0a QqdKjvz&#8221; will instantly recognize that that isn&#8217;t English (even though it is composed entirely of English letters). By studying lots of &#8220;typical&#8221; text, a computer algorithm can simulate this kind of fluency and make an educated guess about a text&#8217;s language.
ja:<p>一般論としてはイエスだ。とはいえ、一部のエンコーディングは特定の言語に最適化されていて、そして言語というものは何らかの規則性を持っているものだ。文章のあちこちに現れる文字列もあれば、言葉として意味をなさない文字列もある。英語に堪能な人が新聞を開いて &#8220;txzqJv 2!dasd0a QqdKjvz&#8221; という文章を見つけたら、（文章自体はすべて英語の文字で構成されているけれども）これは英語の文章ではないと即座に認識できるだろう。この種の言語認識は、大量の「典型的」な文章の解析を行えば、統計的なアルゴリズムによってシミュレートすることができるので、文章が用いている言語をある程度推測することができる。


en:<p>In other words, encoding detection is really language detection, combined with knowledge of which languages tend to use which character encodings.
ja:<p>言い換えれば、文字コードの検出というのは、実際には言語の検出に、どの言語がどの文字コードを使う傾向にあるかという知識を組み合わせたものと言える。


en:<h3 id=faq.who>Does Such An Algorithm Exist?</h3>
ja:<h3 id=faq.who>そういうアルゴリズムは実際に存在するの？</h3>


en:<p>As it turns out, yes. All major browsers have character encoding auto-detection, because the web is full of pages that have no encoding information whatsoever. <a href=http://lxr.mozilla.org/seamonkey/source/extensions/universalchardet/src/base/>Mozilla Firefox contains an encoding auto-detection library</a> which is open source. <a href=http://chardet.feedparser.org/>I ported the library to Python 2</a> and dubbed it the <code>chardet</code> module. This chapter will take you step-by-step through the process of porting the <code>chardet</code> module from Python 2 to Python 3.
ja:<p>実際のところ、イエスだ。主要なウェブブラウザはどれも文字コードの自動検出機能を持っている。というのも、ウェブは文字コードの情報を一切宣言していないページで満ちあふれているからだ。<a href=http://lxr.mozilla.org/seamonkey/source/extensions/universalchardet/src/base/>Mozilla Firefoxには、文字コードの自動検出を行うオープンソースのライブラリが組み込まれている</a>。<a href=http://chardet.feedparser.org/>私はこのライブラリをPython 2に移植し</a>、それに<code>chardet</code>モジュールという名前を付けた。この章は、<code>chardet</code>モジュールをPython 2からPython 3へ移植する過程をステップバイステップで説明する。


en:<h2 id=divingin2>Introducing The <code>chardet</code> Module</h2>
ja:<h2 id=divingin2><code>chardet</code>モジュールのご紹介</h2>


en:<p>Before we set off porting the code, it would help if you understood how the code worked! This is a brief guide to navigating the code itself. The <code>chardet</code> library is too large to include inline here, but you can <a href=http://chardet.feedparser.org/download/>download it from <code>chardet.feedparser.org</code></a>.
ja:<p>コードの移植に取りかかるまえに、それがどのように動作しているのかを理解してもらうのがいいだろう。この節は、コード自体を案内する短いガイドになっている。サイズが大きすぎるため、<code>chardet</code>ライブラリをここに載せることはできないが、<a href=https://pypi.python.org/pypi/chardet><code>pypi.python.org/pypi/chardet</code>からダウンロード</a>することができる。


en:<aside>Encoding detection is really language detection in drag.</aside>
ja:<aside>文字コードの検出は、実際には言語の検出が女装したものといえる。</aside>


en:<p>The main entry point for the detection algorithm is <code>universaldetector.py</code>, which has one class, <code>UniversalDetector</code>. (You might think the main entry point is the <code>detect</code> function in <code>chardet/__init__.py</code>, but that&#8217;s really just a convenience function that creates a <code>UniversalDetector</code> object, calls it, and returns its result.)
ja:<p>検出アルゴリズムのメインエントリポイントは<code>universaldetector.py</code>であり、そこには<code>UniversalDetector</code>というクラスが1つだけ定義さている（メインエントリポイントは<code>chardet/__init__.py</code>の<code>detect</code>関数だと思ったかもしれないが、実はそれはユーザの便宜のために用意された関数にすぎない。この関数は、<code>UniversalDetector</code>オブジェクトを作成した上で呼び出し、その結果を返すという処理だけを行う）。


en:<p>There are 5 categories of encodings that <code>UniversalDetector</code> handles:
ja:<p><code>UniversalDetector</code>が扱う文字コードは5つのカテゴリに分けられる：


en:<li><abbr>UTF-n</abbr> with a Byte Order Mark (<abbr>BOM</abbr>). This includes <abbr>UTF-8</abbr>, both Big-Endian and Little-Endian variants of <abbr>UTF-16</abbr>, and all 4 byte-order variants of <abbr>UTF-32</abbr>.
ja:<li>バイトオーダーマーク (<abbr>BOM</abbr>) の付いた<abbr>UTF-n</abbr>。これには<abbr>UTF-8</abbr>、ビッグエンディアンとリトルエンディアンの<abbr>UTF-16</abbr>、4種類のバイトオーダーの<abbr>UTF-32</abbr>が含まれる。


en:<li>Escaped encodings, which are entirely 7-bit <abbr>ASCII</abbr> compatible, where non-<abbr>ASCII</abbr> characters start with an escape sequence. Examples: <abbr>ISO-2022-JP</abbr> (Japanese) and <abbr>HZ-GB-2312</abbr> (Chinese).
ja:<li>エスケープを利用した文字コード。これは7ビット<abbr>ASCII</abbr>と完全な互換性をもち、非<abbr>ASCII</abbr>文字はエスケープシーケンスで開始される。例：<abbr>ISO-2022-JP</abbr>（日本語）と<abbr>HZ-GB-2312</abbr>（中国語）。


en:<li>Multi-byte encodings, where each character is represented by a variable number of bytes. Examples: <abbr>Big5</abbr> (Chinese), <abbr>SHIFT_JIS</abbr> (Japanese), <abbr>EUC-KR</abbr> (Korean), and <abbr>UTF-8</abbr> without a <abbr>BOM</abbr>.
ja:<li>マルチバイトの文字コード。個々の文字が可変個のバイトで表現される。例：<abbr>Big5</abbr>（中国語）、<abbr>SHIFT_JIS</abbr> （日本語）、<abbr>EUC-KR</abbr>（韓国語）、<abbr>BOM</abbr>のない<abbr>UTF-8</abbr>。


en:<li>Single-byte encodings, where each character is represented by one byte. Examples: <abbr>KOI8-R</abbr> (Russian), <abbr>windows-1255</abbr> (Hebrew), and <abbr>TIS-620</abbr> (Thai).
ja:<li>シングルバイトの文字コード。個々の文字が1バイトで表現される。例：<abbr>KOI8-R</abbr>（ロシア語）、<abbr>windows-1255</abbr>（ヘブライ語）、<abbr>TIS-620</abbr>（タイ語）。


en:<li><abbr>windows-1252</abbr>, which is used primarily on Microsoft Windows by middle managers who wouldn&#8217;t know a character encoding from a hole in the ground.
ja:<li><abbr>windows-1252</abbr>。主にWindows上で用いられている文字コードで、文字コードのことを理解しようとしないマヌケな中間管理職が使っている。


en:<h3 id=how.bom><abbr>UTF-n</abbr> With A <abbr>BOM</abbr></h3>
ja:<h3 id=how.bom><abbr>BOM</abbr>の付いた<abbr>UTF-n</abbr></h3>


en:<p>If the text starts with a <abbr>BOM</abbr>, we can reasonably assume that the text is encoded in <abbr>UTF-8</abbr>, <abbr>UTF-16</abbr>, or <abbr>UTF-32</abbr>. (The <abbr>BOM</abbr> will tell us exactly which one; that&#8217;s what it&#8217;s for.)  This is handled inline in <code>UniversalDetector</code>, which returns the result immediately without any further processing.
ja:<p>テキストが<abbr>BOM</abbr>で始まる場合は、そのテキストが<abbr>UTF-8</abbr>、<abbr>UTF-16</abbr>、<abbr>UTF-32</abbr>のどれかでエンコードされていると合理的に推測できる（さらに<abbr>BOM</abbr>はこれらのうちのどれであるかを教えてくれる。そもそも<abbr>BOM</abbr>はそのためのものだ）。この識別は<code>UniversalDetector</code>の中でインラインで行われ、<code>UniversalDetector</code>は、それ以降の処理を行わずに即座に結果を返す。


en:<h3 id=how.esc>Escaped Encodings</h3>
ja:<h3 id=how.esc>エスケープを利用した文字コード</h3>


en:<p>If the text contains a recognizable escape sequence that might indicate an escaped encoding, <code>UniversalDetector</code> creates an <code>EscCharSetProber</code> (defined in <code>escprober.py</code>) and feeds it the text.
ja:<p>エスケープを利用した文字コードであることを示すようなエスケープシーケンスがテキストの中に見つかった場合には、<code>UniversalDetector</code>が<code>EscCharSetProber</code>（<code>escprober.py</code>で定義されている）を作成し、そこにテキストを流し込む。


en:<p><code>EscCharSetProber</code> creates a series of state machines, based on models of <abbr>HZ-GB-2312</abbr>, <abbr>ISO-2022-CN</abbr>, <abbr>ISO-2022-JP</abbr>, and <abbr>ISO-2022-KR</abbr> (defined in <code>escsm.py</code>). <code>EscCharSetProber</code> feeds the text to each of these state machines, one byte at a time. If any state machine ends up uniquely identifying the encoding, <code>EscCharSetProber</code> immediately returns the positive result to <code>UniversalDetector</code>, which returns it to the caller. If any state machine hits an illegal sequence, it is dropped and processing continues with the other state machines.
ja:<p><code>EscCharSetProber</code>は、<abbr>HZ-GB-2312</abbr>、<abbr>ISO-2022-CN</abbr>、<abbr>ISO-2022-JP</abbr>、<abbr>ISO-2022-KR</abbr>のモデル（<code>escsm.py</code>で定義されている）に基づいた、一連の状態機械 (state machine) を作成する。<code>EscCharSetProber</code>は、これらの状態機械にテキストを1バイトずつ流し込んでいく。状態機械のどれかが文字コードを一意に特定する結果になったときは、<code>EscCharSetProber</code>は「文字コードを特定した」という結果を即座に<code>UniversalDetector</code>に返し、<code>UniversalDetector</code>はその結果を呼び出し元に返す。各々の状態機械は、その文字コードで解釈できないシーケンスに突き当たった時点で脱落させられ、以後の処理は残りの状態機械だけで続けられる。


en:<h3 id=how.mb>Multi-Byte Encodings</h3>
ja:<h3 id=how.mb>マルチバイトの文字コード</h3>


en:<p>Assuming no <abbr>BOM</abbr>, <code>UniversalDetector</code> checks whether the text contains any high-bit characters. If so, it creates a series of &#8220;probers&#8221; for detecting multi-byte encodings, single-byte encodings, and as a last resort, <code>windows-1252</code>.
ja:<p><abbr>BOM</abbr>がないときは、<code>UniversalDetector</code>はテキストに0x80〜0xFFのバイトが含まれていないかをチェックする。含まれている場合は、<code>UniversalDetector</code>はマルチバイト文字列と、シングルバイト文字列と、最後の手段である<code>windows-1252</code>を検出するための一連の「調査器 (prober)」を作成する。


en:<p>The multi-byte encoding prober, <code>MBCSGroupProber</code> (defined in <code>mbcsgroupprober.py</code>), is really just a shell that manages a group of other probers, one for each multi-byte encoding: <abbr>Big5</abbr>, <abbr>GB2312</abbr>, <abbr>EUC-TW</abbr>, <abbr>EUC-KR</abbr>, <abbr>EUC-JP</abbr>, <abbr>SHIFT_JIS</abbr>, and <abbr>UTF-8</abbr>. <code>MBCSGroupProber</code> feeds the text to each of these encoding-specific probers and checks the results. If a prober reports that it has found an illegal byte sequence, it is dropped from further processing (so that, for instance, any subsequent calls to <code>UniversalDetector</code>.<code>feed()</code> will skip that prober). If a prober reports that it is reasonably confident that it has detected the encoding, <code>MBCSGroupProber</code> reports this positive result to <code>UniversalDetector</code>, which reports the result to the caller.
ja:<p>マルチバイトエンコーディングの調査器<code>MBCSGroupProber</code>（<code>mbcsgroupprober.py</code>で定義されている）は、実際には各々のマルチバイト文字コード（<abbr>Big5</abbr>・<abbr>GB2312</abbr>・<abbr>EUC-TW</abbr>・<abbr>EUC-KR</abbr>・<abbr>EUC-JP</abbr>・<abbr>SHIFT_JIS</abbr>・<abbr>UTF-8</abbr>）の調査器からなるグループを管理するための単なるまとめ役に過ぎない。<code>MBCSGroupProber</code>は、これら文字コード固有の調査器それぞれにテキストを流し込み、その結果をチェックする。調査器が、解釈できないバイト列を見つけたと報告したら、その調査器は以後の処理から脱落させられる（つまり、例えば、以後の<code>UniversalDetector</code>.<code>feed()</code>の呼び出しはその調査器をスキップする）。調査器の一つが、これでまず間違いないという文字コードを検出したら、<code>MBCSGroupProber</code>はその結果を<code>UniversalDetector</code>に報告し、さらに<code>UniversalDetector</code>はこれを呼び出し元に報告する。


en:<p>Most of the multi-byte encoding probers are inherited from <code>MultiByteCharSetProber</code> (defined in <code>mbcharsetprober.py</code>), and simply hook up the appropriate state machine and distribution analyzer and let <code>MultiByteCharSetProber</code> do the rest of the work. <code>MultiByteCharSetProber</code> runs the text through the encoding-specific state machine, one byte at a time, to look for byte sequences that would indicate a conclusive positive or negative result. At the same time, <code>MultiByteCharSetProber</code> feeds the text to an encoding-specific distribution analyzer.
ja:<p>マルチバイト文字コードの調査器のほとんどは<code>MultiByteCharSetProber</code>（<code>mbcharsetprober.py</code>で定義されている）を継承している。これらの調査器は適切な状態機械と分布解析器をセットしているだけで、残りの仕事は<code>MultiByteCharSetProber</code>がやっている。<code>MultiByteCharSetProber</code>は、テキストを文字コード固有の状態機械に1文字ずつ流し込んでいき、「確実にこの文字コードが使われている」ないし「この文字コードでは絶対にない」ということを指し示すバイトシーケンスを探す。それと同時に<code>MultiByteCharSetProber</code>は、テキストを文字コード固有の分布解析器にも流し込んでいく。


en:<p>The distribution analyzers (each defined in <code>chardistribution.py</code>) use language-specific models of which characters are used most frequently. Once <code>MultiByteCharSetProber</code> has fed enough text to the distribution analyzer, it calculates a confidence rating based on the number of frequently-used characters, the total number of characters, and a language-specific distribution ratio. If the confidence is high enough, <code>MultiByteCharSetProber</code> returns the result to <code>MBCSGroupProber</code>, which returns it to <code>UniversalDetector</code>, which returns it to the caller.
ja:<p>分布解析器（各々は<code>chardistribution.py</code>で定義されている）は、どの文字が頻繁に使われるのかについての言語固有のモデルを持っている。<code>MultiByteCharSetProber</code>が分布解析器に十分なテキストを流し込むと、「よく使われる文字」の出現回数、テキストの総文字数、言語固有の分布比に基づいて信頼度を計算する。信頼度が十分に高い場合、<code>MultiByteCharSetProber</code>はその結果を<code>MBCSGroupProber</code>に返し、<code>MBCSGroupProber</code>はそれを<code>UniversalDetector</code>に返し、<code>UniversalDetector</code>はそれを呼び出し元に返す。


en:<p>The case of Japanese is more difficult. Single-character distribution analysis is not always sufficient to distinguish between <code>EUC-JP</code> and <code>SHIFT_JIS</code>, so the <code>SJISProber</code> (defined in <code>sjisprober.py</code>) also uses 2-character distribution analysis. <code>SJISContextAnalysis</code> and <code>EUCJPContextAnalysis</code> (both defined in <code>jpcntx.py</code> and both inheriting from a common <code>JapaneseContextAnalysis</code> class) check the frequency of Hiragana syllabary characters within the text. Once enough text has been processed, they return a confidence level to <code>SJISProber</code>, which checks both analyzers and returns the higher confidence level to <code>MBCSGroupProber</code>.
ja:<p>日本語の場合はもっと難しい。1文字の分布解析は<code>EUC-JP</code>と<code>SHIFT_JIS</code>を区別するのには不十分なことがあるので、<code>SJISProber</code>（<code>sjisprober.py</code>で定義されている）は2文字ごとの分布解析も行っている。<code>SJISContextAnalysis</code>と<code>EUCJPContextAnalysis</code>（両者は<code>jpcntx.py</code>で定義されていて共通の<code>JapaneseContextAnalysis</code>クラスを継承している）は、テキストに含まれているひらがなの頻度をチェックする。十分な量のテキストが処理されると、その信頼度が<code>SJISProber</code>に返され、<code>SJISProber</code>は両方の分析器をチェックして、高いほうの信頼度を<code>MBCSGroupProber</code>に返す。


en:<h3 id=how.sb>Single-Byte Encodings</h3>
ja:<h3 id=how.sb>シングルバイトの文字コード</h3>


en:<aside>Seriously, where&#8217;s my Unicode pony?</aside>
ja:<aside>冗談抜きで、私のUnicodeポニーはどこにいるんだ？</aside>


en:<p>The single-byte encoding prober, <code>SBCSGroupProber</code> (defined in <code>sbcsgroupprober.py</code>), is also just a shell that manages a group of other probers, one for each combination of single-byte encoding and language: <code>windows-1251</code>, <code>KOI8-R</code>, <code>ISO-8859-5</code>, <code>MacCyrillic</code>, <code>IBM855</code>, and <code>IBM866</code> (Russian); <code>ISO-8859-7</code> and <code>windows-1253</code> (Greek); <code>ISO-8859-5</code> and <code>windows-1251</code> (Bulgarian); <code>ISO-8859-2</code> and <code>windows-1250</code> (Hungarian); <code>TIS-620</code> (Thai); <code>windows-1255</code> and <code>ISO-8859-8</code> (Hebrew).
ja:<p>シングルバイトの文字コード調査器<code>SBCSGroupProber</code>（<code>sbcsgroupprober.py</code>で定義されている）も、他の調査器のまとめ役にすぎない。束ねられている各々の調査器は、特定の言語・文字コードの組み合わせに対応している：<code>windows-1251</code>・<code>KOI8-R</code>・<code>ISO-8859-5</code>・<code>MacCyrillic</code>・<code>IBM855</code>・<code>IBM866</code> (ロシア語)、<code>ISO-8859-7</code>・<code>windows-1253</code> (ギリシャ語)、<code>ISO-8859-5</code>・<code>windows-1251</code> (ブルガリア語)、<code>ISO-8859-2</code>・<code>windows-1250</code>（ハンガリー語）; <code>TIS-620</code> (タイ語); <code>windows-1255</code>・<code>ISO-8859-8</code>（ヘブライ語）


en:<p><code>SBCSGroupProber</code> feeds the text to each of these encoding+language-specific probers and checks the results. These probers are all implemented as a single class, <code>SingleByteCharSetProber</code> (defined in <code>sbcharsetprober.py</code>), which takes a language model as an argument. The language model defines how frequently different 2-character sequences appear in typical text. <code>SingleByteCharSetProber</code> processes the text and tallies the most frequently used 2-character sequences. Once enough text has been processed, it calculates a confidence level based on the number of frequently-used sequences, the total number of characters, and a language-specific distribution ratio.
ja:<p><code>SBCSGroupProber</code>は、テキストをこれらの文字コード+言語に固有の調査器に入力し、その結果をチェックする。これらの調査器はすべて単一のクラス<code>SingleByteCharSetProber</code>（<code>sbcharsetprober.py</code>で定義されている）として実装されていて、このクラスは引数として言語モデルを受け取る。この言語モデルは、異なる2文字の組み合わせが典型的なテキストにおいてどのくらいの頻度で出現するのかを定義している。<code>SingleByteCharSetProber</code>はテキストを処理し、「よく使われる2文字の組み合わせ」が文章にいくつ現れているかを数える。十分なテキストが処理されると、<code>SingleByteCharSetProber</code>は、よく使われる2文字組の出現回数と、テキストの総文字数と、言語固有の分布比に基づいて信頼度の計算を行う。


en:<p>Hebrew is handled as a special case. If the text appears to be Hebrew based on 2-character distribution analysis, <code>HebrewProber</code> (defined in <code>hebrewprober.py</code>) tries to distinguish between Visual Hebrew (where the source text actually stored &#8220;backwards&#8221; line-by-line, and then displayed verbatim so it can be read from right to left) and Logical Hebrew (where the source text is stored in reading order and then rendered right-to-left by the client). Because certain characters are encoded differently based on whether they appear in the middle of or at the end of a word, we can make a reasonable guess about direction of the source text, and return the appropriate encoding (<code>windows-1255</code> for Logical Hebrew, or <code>ISO-8859-8</code> for Visual Hebrew).
ja:<p>ヘブライ語は特別なケースとして扱われる。2文字組の分布解析に基づいてテキストがヘブライ語だと思われる場合は、<code>HebrewProber</code>（<code>hebrewprober.py</code>で定義されている）を使って、ビジュアルヘブライ（ソーステキストが行ごとに「逆向き」に格納されていて、そのまま表示すれば右から左に読めるようになっている）とロジカルヘブライ（ソーステキストは読む順番で格納され、クライアントによって右から左に表示される）の判別を行う。いくつかの文字は単語の中間に現れるのか単語の末尾に現れるのかによって異なる符号化処理がなされるので、これを使えば元のテキストの方向をほぼ確実に識別することができるのだ。その上で、適切な文字コード（ロジカルヘブライ用の<code>windows-1255</code>またはビジュアルヘブライ用の<code>ISO-8859-8</code>）を返す。


en:<h3 id=how.windows1252><code>windows-1252</code></h3>
ja:<h3 id=how.windows1252><code>windows-1252</code></h3>


en:<p>If <code>UniversalDetector</code> detects a high-bit character in the text, but none of the other multi-byte or single-byte encoding probers return a confident result, it creates a <code>Latin1Prober</code> (defined in <code>latin1prober.py</code>) to try to detect English text in a <code>windows-1252</code> encoding. This detection is inherently unreliable, because English letters are encoded in the same way in many different encodings. The only way to distinguish <code>windows-1252</code> is through commonly used symbols like smart quotes, curly apostrophes, copyright symbols, and the like. <code>Latin1Prober</code> automatically reduces its confidence rating to allow more accurate probers to win if at all possible.
ja:<p><code>UniversalDetector</code>が0x80〜0xFFのバイトをテキストから検出したにもかかわらず、他のマルチバイトやシングルバイトの調査器が一つも信頼できる結果を返さなかった場合は、<code>windows-1252</code>でエンコードされた英文テキストかどうかを判別するために<code>Latin1Prober</code>（<code>latin1prober.py</code>で定義されている）を作成する。この検出は本質的に信頼できないものでしかない。というのも、英語の文字をエンコードする方法は大抵の文字コードで同じだからだ。<code>windows-1252</code>を識別するには、スマートクォート、カールしたアポストロフィ、コピーライト記号、などなどの一般的に使われる記号に頼るしかない。<code>Latin1Prober</code>は、もっと正確な調査器にできるだけ勝たせてあげるために、自分の信頼度を自動的に減少させるようになっている。


en:<h2 id=running2to3>Running <code>2to3</code></h2>
ja:<h2 id=running2to3><code>2to3</code>を実行する</h2>


en:<p>We&#8217;re going to migrate the <code>chardet</code> module from Python 2 to Python 3. Python 3 comes with a utility script called <code>2to3</code>, which takes your actual Python 2 source code as input and auto-converts as much as it can to Python 3. In some cases this is easy&nbsp;&mdash;&nbsp;a function was renamed or moved to a different module&nbsp;&mdash;&nbsp;but in other cases it can get pretty complex. To get a sense of all that it <em>can</em> do, refer to the appendix, <a href=porting-code-to-python-3-with-2to3.html>Porting code to Python 3 with <code>2to3</code></a>. In this chapter, we&#8217;ll start by running <code>2to3</code> on the <code>chardet</code> package, but as you&#8217;ll see, there will still be a lot of work to do after the automated tools have performed their magic.
ja:<p>これより、<code>chardet</code>モジュールをPython 2からPython 3に移植する。python 3には<code>2to3</code>と呼ばれるユーティリティスクリプトが付属している。このスクリプトは、実際のPython 2のソースコードを受け取って、Python 3で動くように可能な限り自動変換してくれるものだ。変換が容易であるケース（関数の名前が変更されたとか、他のモジュールに移動されたなど）もあれば、かなり複雑なものになるケースもある。このツールがどこまでできるのかを知るには、Appendixの<a href=porting-code-to-python-3-with-2to3.html><code>2to3</code>を使ってコードをPython 3に移植する</a>を参照してほしい。この章は、<code>2to3</code>を<code>chardet</code>パッケージに対して実行することから始めるが、後で分かるように、この自動化されたツールが魔法を披露したあとでも、私たちがやらなければならない仕事はまだ大量に存在する。


en:<p>The main <code>chardet</code> package is split across several different files, all in the same directory. The <code>2to3</code> script makes it easy to convert multiple files at once: just pass a directory as a command line argument, and <code>2to3</code> will convert each of the files in turn.
ja:<p><code>chardet</code>パッケージは複数のファイルに分割されていて、それらのファイルはすべて同じディレクトリに納められている。<code>2to3</code>は、簡単に複数のファイルを一度で変換できるようになっている。ディレクトリをコマンドライン引数として渡すだけで、<code>2to3</code>は各ファイルを次々に変換してくれるのだ。


en:<p>Now run the <code>2to3</code> script on the testing harness, <code>test.py</code>.
ja:<p>今度は、自動テストスクリプトである<code>test.py</code>に対して<code>2to3</code>を実行しよう。


en:<p>Well, that wasn&#8217;t so hard. Just a few imports and print statements to convert. Speaking of which, what <em>was</em> the problem with all those import statements? To answer that, you need to understand how the <code>chardet</code> module is split into multiple files.
ja:<p>それほど大変なものではなかった。いくつかのインポート文とprint文を変換しただけだ。ところで、そもそもこのインポート文の何がまずかったのだろう。それに答えるには、<code>chardet</code>モジュールがどのように複数のファイルに分割されているのかを知らなければならない。


en:<h2 id=multifile-modules>A Short Digression Into Multi-File Modules</h2>
ja:<h2 id=multifile-modules>マルチファイルモジュールの話に少し脱線</h2>


en:<p><code>chardet</code> is a <i>multi-file module</i>. I could have chosen to put all the code in one file (named <code>chardet.py</code>), but I didn&#8217;t. Instead, I made a directory (named <code>chardet</code>), then I made an <code>__init__.py</code> file in that directory. <em>If Python sees an <code>__init__.py</code> file in a directory, it assumes that all of the files in that directory are part of the same module.</em> The module&#8217;s name is the name of the directory. Files within the directory can reference other files within the same directory, or even within subdirectories. (More on that in a minute.) But the entire collection of files is presented to other Python code as a single module&nbsp;&mdash;&nbsp;as if all the functions and classes were in a single <code>.py</code> file.
ja:<p><code>chardet</code>は複数のファイルで構成されるモジュールだ。これを<code>chardet.py</code>という一つのファイルにまとめることもできたのだが、そうしなかった。その代わりに、私は<code>chardet</code>という名前のディレクトリを作成し、そのディレクトリの中に<code>__init__.py</code>というファイルを置いた。<em>ディレクトリの中に<code>__init__.py</code>というファイルを見つけると、Pythonはそのディレクトリの中にあるファイル全体が1つのモジュールを構成しているものと解釈する</em>。そのディレクトリ名がモジュールの名前になる。ディレクトリの中にあるファイルは、同じディレクトリにある他のファイルを参照できるし、さらにサブディレクトリの中にあるファイルを参照することもできる（詳細はすぐに述べる）。しかしそのファイルの集まり全体は、ほかのPythonコードには単一のモジュールとして見える。あたかもすべての関数とクラスが単一の<code>.py</code>ファイルの中にあるかのように見えるのだ。


en:<p>What goes in the <code>__init__.py</code> file? Nothing. Everything. Something in between. The <code>__init__.py</code> file doesn&#8217;t need to define anything; it can literally be an empty file. Or you can use it to define your main entry point functions. Or you put all your functions in it. Or all but one.
ja:<p>この<code>__init__.py</code>ファイルは何をするのだろうか？ 何もしないかもしれない。すべてのことをするのかもしれない。その中間かもしれない。<code>__init__.py</code>ファイルは一切何も定義しなくてもいい。文字通り空っぽのファイルであってもいいし、メインのエントリーポイントになる関数を定義するために使ってもいいし、全ての関数を入れてもいい。


en:<p><span class=u>&#x261E;</span>A directory with an <code>__init__.py</code> file is always treated as a multi-file module. Without an <code>__init__.py</code> file, a directory is just a directory of unrelated <code>.py</code> files.
ja:<p><span class=u>&#x261E;</span><code>__init__.py</code>ファイルを含むディレクトリは常にマルチファイルモジュールとして扱われる。<code>__init__.py</code>ファイルがなければ、そのディレクトリは、互いに関連が無い<code>.py</code>ファイルが入ったディレクトリとして扱われる。


en:<p>Let&#8217;s see how that works in practice.
ja:<p>実際にどのように動作するのかを見てみよう。


en:<li>Other than the usual class attributes, the only thing in the <code>chardet</code> module is a <code>detect()</code> function.
ja:<li>ふつうのクラス属性を除けば、<code>chardet</code>モジュールの中にあるものは<code>detect()</code>関数だけだ。


en:<li>Here&#8217;s your first clue that the <code>chardet</code> module is more than just a file: the &#8220;module&#8221; is listed as the <code>__init__.py</code> file within the <code>chardet/</code> directory.
ja:<li>これは<code>chardet</code>モジュールが単一のファイルではないことを示す1つ目の証拠だ: この「モジュール」は<code>chardet/</code>ディレクトリにある<code>__init__.py</code>ファイルとして示されている。


en:<p>Let&#8217;s take a peek in that <code>__init__.py</code> file.
ja:<p><code>__init__.py</code> ファイルの中を覗いてみよう。


en:<li>The <code>__init__.py</code> file defines the <code>detect()</code> function, which is the main entry point into the <code>chardet</code> library.
ja:<li>この<code>__init__.py</code>ファイルは<code>detect()</code>関数を定義している。この関数は、<code>chardet</code>ライブラリへのメインのエントリポイントだ。


en:<li>But the <code>detect()</code> function hardly has any code! In fact, all it really does is import the <code>universaldetector</code> module and start using it. But where is <code>universaldetector</code> defined?
ja:<li>しかし、この<code>detect()</code>関数には中身がほとんどない！ 実のところ、この関数が実際にやっているのは、<code>universaldetector</code>モジュールをインポートして、使い始めることだけだ。しかし、<code>universaldetector</code>はどこで定義されているのだろうか？


en:<p>The answer lies in that odd-looking <code>import</code> statement:
ja:<p>その答えはこの奇妙な<code>import</code>文の中にある：


en:<p>Translated into English, that means &#8220;import the <code>universaldetector</code> module; that&#8217;s in the same directory I am,&#8221; where &#8220;I&#8221; is the <code>chardet/__init__.py</code> file. This is called a <i>relative import</i>. It&#8217;s a way for the files within a multi-file module to reference each other, without worrying about naming conflicts with other modules you may have installed in <a href=your-first-python-program.html#importsearchpath>your import search path</a>. This <code>import</code> statement will <em>only</em> look for the <code>universaldetector</code> module within the <code>chardet/</code> directory itself.
ja:<p>これを翻訳すると、「<code>universaldetector</code>モジュールをインポートしてほしい。そのモジュールは私と同じディレクトリにある」という意味になる。ここでの「私」とは、<code>chardet/__init__.py</code>ファイルのことだ。このインポートは<i>相対インポート</i>と呼ばれている。これは、一つのモジュールを構成している複数のファイルが互いを参照する方式の一つで、こうすれば<a href=your-first-python-program.html#importsearchpath>あなたのimport検索パス</a>にインストールされているかもしれない他のモジュールとの名前の衝突を心配しなくてもよくなる。この<code>import</code>文は、<code>chardet/</code>ディレクトリの中にある<code>universaldetector</code>モジュール<em>だけ</em>を探す。


en:<p>These two concepts&nbsp;&mdash;&nbsp;<code>__init__.py</code> and relative imports&nbsp;&mdash;&nbsp;mean that you can break up your module into as many pieces as you like. The <code>chardet</code> module comprises 36 <code>.py</code> files&nbsp;&mdash;&nbsp;36! Yet all you need to do to start using it is <code>import chardet</code>, then you can call the main <code>chardet.detect()</code> function. Unbeknownst to your code, the <code>detect()</code> function is actually defined in the <code>chardet/__init__.py</code> file. Also unbeknownst to you, the <code>detect()</code> function uses a relative import to reference a class defined in <code>chardet/universaldetector.py</code>, which in turn uses relative imports on five other files, all contained in the <code>chardet/</code> directory.
ja:<p>これらの2つの概念、つまり<code>__init__.py</code>と相対インポートは、自分のモジュールを望む限りいくつのピースにでも分解できることを意味している。<code>chardet</code>モジュールは36個の<code>.py</code>ファイルから構成されている。36個だ！ とはいえ、このモジュールを使うのに必要な処理は<code>import chardet</code>だけであり、それだけでメインの<code>chardet.detect()</code>関数を呼び出すことができるようになる。モジュールを使う側からは分からないことだが、この<code>detect()</code>関数は実際には<code>chardet/__init__.py</code>ファイルで定義されている。また、これも気がつかないことだが、<code>detect()</code>関数は相対インポートを使って<code>chardet/universaldetector.py</code>で定義されているクラスを参照している。このファイルはさらに別の5つのファイルを相対インポートしていて、これらのファイルはすべて<code>chardet/</code>ディレクトリにおさまっている。


en:<p><span class=u>&#x261E;</span>If you ever find yourself writing a large library in Python (or more likely, when you realize that your small library has grown into a large one), take the time to refactor it into a multi-file module. It&#8217;s one of the many things Python is good at, so take advantage of it.
ja:<p><span class=u>&#x261E;</span>Pythonで大きなライブラリを書いているなら（というよりも書いているライブラリが大きくなってきたら）、時間を割いて、そのライブラリをマルチファイルモジュールへとリファクタリングするといい。これはPythonが得意なことの1つなので、ぜひ活用しよう。


en:<h2 id=manual>Fixing What <code>2to3</code> Can&#8217;t</h2>
ja:<h2 id=manual><code>2to3</code>にはできないことを修正する</h2>


en:<h3 id=falseisinvalidsyntax><code>False</code> is invalid syntax</h3>
ja:<h3 id=falseisinvalidsyntax><code>False</code> is invalid syntax</h3>


en:<aside>You do have tests, right?</aside>
ja:<aside>テストは用意されている、よね？</aside>


en:<p>Now for the real test: running the test harness against the test suite. Since the test suite is designed to cover all the possible code paths, it&#8217;s a good way to test our ported code to make sure there aren&#8217;t any bugs lurking anywhere.
ja:<p>さて実際のテストを行おう。自動テストフレームワークを実行してテストスイートを検証するのだ。このテストスイートは考え得るすべてのコードパスを網羅するように設計されているので、これは私たちが移植したコードのどこにもバグが潜んでいないことを確認するための良い方法だ。


en:<p>Hmm, a small snag. In Python 3, <code>False</code> is a reserved word, so you can&#8217;t use it as a variable name. Let&#8217;s look at <code>constants.py</code> to see where it&#8217;s defined. Here&#8217;s the original version from <code>constants.py</code>, before the <code>2to3</code> script changed it:
ja:<p>うーん、これはちょっとした障害だ。Python 3では<code>False</code>が予約語になったので、これを変数名として使うことはできない。これが定義されている場所を見るために、<code>constants.py</code>を見てみよう。以下は<code>2to3</code>によって変更される前の、元のバージョンの<code>constants.py</code>だ。


en:<p>This piece of code is designed to allow this library to run under older versions of Python 2. Prior to Python 2.3, Python had no built-in <code>bool</code> type. This code detects the absence of the built-in constants <code>True</code> and <code>False</code>, and defines them if necessary.
ja:<p>このコードは、ライブラリがPython 2の古いバージョンでも動くようにするためのものだ。Python 2.3以前では、Pythonは組み込みの<code>bool</code>型を持っていなかった。このコードは組み込み定数<code>True</code>と<code>False</code>が存在しないことを検出し、必要であればそれらを定義する。


en:<p>However, Python 3 will always have a <code>bool</code> type, so this entire code snippet is unnecessary. The simplest solution is to replace all instances of <code>constants.True</code> and <code>constants.False</code> with <code>True</code> and <code>False</code>, respectively, then delete this dead code from <code>constants.py</code>.
ja:<p>しかしながら、Python 3には必ず<code>bool</code>型があるので、この部分のコードはすべて要らなくなる。最も簡単な解決方法は、ライブラリの中で<code>constants.True</code>か<code>constants.False</code>を使っている部分を、それぞれ<code>True</code>と<code>False</code>で書き換えて、この死んだコードを<code>constants.py</code>から取り除くことだ。


en:<p>So this line in <code>universaldetector.py</code>:
ja:<p>よって、<code>universaldetector.py</code>の次の行は：


en:<p>Becomes
ja:<p>こうなる


en:<p>Ah, wasn&#8217;t that satisfying? The code is shorter and more readable already.
ja:<p>うむ。こんな感じで十分かな。コードは以前よりも短くて読みやすいものになっている。


en:<h3 id=nomodulenamedconstants>No module named <code>constants</code></h3>
ja:<h3 id=nomodulenamedconstants>No module named <code>constants</code></h3>


en:<p>Time to run <code>test.py</code> again and see how far it gets.
ja:<p>もう一度<code>test.py</code>を実行して、どこまで行けるか見てみよう。


en:<p>What&#8217;s that you say? No module named <code>constants</code>? Of course there&#8217;s a module named <code>constants</code>. It&#8217;s right there, in <code>chardet/constants.py</code>.
ja:<p>何だって？ <code>constants</code>という名前のモジュールがない？ 言うまでもなく<code>constants</code>という名前のモジュールは存在している。ほら、確かに<code>chardet/constants.py</code>にあるじゃないか。


en:<p>Remember when the <code>2to3</code> script fixed up all those import statements? This library has a lot of relative imports&nbsp;&mdash;&nbsp;that is, <a href=#multifile-modules>modules that import other modules within the same library</a>&nbsp;&mdash;&nbsp;but <em>the logic behind relative imports has changed in Python 3</em>. In Python 2, you could just <code>import constants</code> and it would look in the <code>chardet/</code> directory first. In Python 3, <a href=http://www.python.org/dev/peps/pep-0328/>all import statements are absolute by default</a>. If you want to do a relative import in Python 3, you need to be explicit about it:
ja:<p><code>2to3</code>スクリプトがこれらのインポート文を修正したときのことを覚えているだろうか？ このライブラリは相対インポートを多用していたが（つまり、<a href=#multifile-modules>同じライブラリの中にある他のモジュールをインポートするモジュール</a>がたくさんあったが）、<em>相対インポートの仕組みはPython 3で変更されている</em>。Python2では、<code>import constants</code>と書けば、まずは<code>chardet/</code>ディレクトリから<code>constants</code>モジュールの探索が開始された。しかし、Python 3では、<a href=http://www.python.org/dev/peps/pep-0328/>すべてのインポート文はデフォルトでは絶対インポートだと解釈される</a>（従って、<code>sys.path</code>上にあるモジュールしか検索されない）。Python 3で相対インポートを使いたければ、そのことを明示しなければならない。


en:<p>But wait. Wasn&#8217;t the <code>2to3</code> script supposed to take care of these for you? Well, it did, but this particular import statement combines two different types of imports into one line: a relative import of the <code>constants</code> module within the library, and an absolute import of the <code>sys</code> module that is pre-installed in the Python standard library. In Python 2, you could combine these into one import statement. In Python 3, you can&#8217;t, and the <code>2to3</code> script is not smart enough to split the import statement into two.
ja:<p>しかし待って欲しい。これらは<code>2to3</code>スクリプトがやってくれるはずではなかったのか？ そう、<code>2to3</code>はこれをやってくれるのだが、このインポート文では2種類のインポートを1行で行っている。ライブラリ内の<code>constants</code>モジュールを相対インポートしている一方で、標準モジュールとしてインストールさている<code>sys</code>を絶対インポートしているのだ。Python 2ではこの2つのインポート文を1行にまとめて書くことができたのだが、Python 3ではそれが許されていない。そして、<code>2to3</code>スクリプトはこのインポート文を2行に分割できるほど賢くないのだ。


en:<p>The solution is to split the import statement manually. So this two-in-one import:
ja:<p>解決方法はこのインポート文を手作業で分割することだ。したがって、次の2つが1つになっているインポート文は：


en:<p>Needs to become two separate imports:
ja:<p>2つの別々のインポート文にしなくてはいけない：


en:<p>There are variations of this problem scattered throughout the <code>chardet</code> library. In some places it&#8217;s &#8220;<code>import constants, sys</code>&#8221;; in other places, it&#8217;s &#8220;<code>import constants, re</code>&#8221;. The fix is the same: manually split the import statement into two lines, one for the relative import, the other for the absolute import.
ja:<p>これと同じ問題は、<code>chardet</code>ライブラリのあらゆる部分に見られる。ある部分では &#8220;<code>import constants, sys</code>&#8221; としているし、他の部分では &#8220;<code>import constants, re</code>&#8221; としている。修正方法はすべて同じだ。手作業でインポート文を2行に分割し、1つは相対インポート、もう一つは絶対インポートにすればいい。


en:<p>Onward!
ja:<p>次へ進もう！


en:<h3 id=namefileisnotdefined>Name <var>'file'</var> is not defined</h3>
ja:<h3 id=namefileisnotdefined>Name <var>'file'</var> is not defined</h3>


en:<aside>open() is the new file(). PapayaWhip is the new black.</aside>
ja:<aside>open()は新しいfile()だ。PapayaWhip（パパイヤホイップ）は新しい流行色だ。</aside>


en:<p>And here we go again, running <code>test.py</code> to try to execute our test cases&hellip;
ja:<p>もう一度、<code>test.py</code>を走らせてテストケースを実行してみよう&hellip;&hellip;


en:<p>This one surprised me, because I&#8217;ve been using this idiom as long as I can remember. In Python 2, the global <code>file()</code> function was an alias for the <code>open()</code> function, which was the standard way of <a href=files.html#reading>opening text files for reading</a>. In Python 3, the global <code>file()</code> function no longer exists, but the <code>open()</code> function still exists.
ja:<p>このエラーには驚かされた。なぜなら、私はこのイディオムをずっと昔から使いつづけてきたからだ。Python 2では、グローバルの<code>file()</code>関数は<code>open()</code>関数のエイリアスであり、これは<a href=files.html#reading>テキストファイルを読み込み用に開く</a>ための標準的な方法だった。Python 3では、グローバルの<code>file()</code>関数はもはや存在せず、<code>open()</code>関数だけしかない。


en:<p>Thus, the simplest solution to the problem of the missing <code>file()</code> is to call the <code>open()</code> function instead:
ja:<p>したがって、<code>file()</code>関数が見つからないという問題の最も簡単な解決方法は、<code>file()</code>の代わりに<code>open()</code>関数を呼び出すことだ。


en:<p>And that&#8217;s all I have to say about that.
ja:<p>これに関して言うべきことはこれだけだ。


en:<h3 id=cantuseastringpattern>Can&#8217;t use a string pattern on a bytes-like object</h3>
ja:<h3 id=cantuseastringpattern>Can&#8217;t use a string pattern on a bytes-like object</h3>


en:<p>Now things are starting to get interesting. And by &#8220;interesting,&#8221; I mean &#8220;confusing as all hell.&#8221;
ja:<p>面白くなり始めてきた。「面白い」っていうのは「うんざりするほどややこしい」という意味だけどね。


en:<p>To debug this, let&#8217;s see what <var>self._highBitDetector</var> is. It&#8217;s defined in the <var>__init__</var> method of the <var>UniversalDetector</var> class:
ja:<p>これをデバッグするために、<var>self._highBitDetector</var>が何なのかを見てみよう。これは<var>UniversalDetector</var>クラスの<var>__init__</var>メソッドで定義されている：


en:<p>This pre-compiles a regular expression designed to find non-<abbr>ASCII</abbr> characters in the range 128&ndash;255 (0x80&ndash;0xFF). Wait, that&#8217;s not quite right; I need to be more precise with my terminology. This pattern is designed to find non-<abbr>ASCII</abbr> <em>bytes</em> in the range 128-255.
ja:<p>これは128&ndash;255 (0x80&ndash;0xFF) の範囲にある非<abbr>ASCII</abbr>文字を見つけるための正規表現をプリコンパイルしている。いや、待って、その言い方は正しくない。もっと正確な言葉を使おう。このパターンは、128&ndash;255の範囲にある非<abbr>ASCII</abbr>の<em>バイト</em>を見つけ出すためのものだ。


en:<p>And therein lies the problem.
ja:<p>そして、そこに問題がひそんでいる。


en:<p>In Python 2, a string was an array of bytes whose character encoding was tracked separately. If you wanted Python 2 to keep track of the character encoding, you had to use a Unicode string (<code>u''</code>) instead. But in Python 3, a string is always what Python 2 called a Unicode string&nbsp;&mdash;&nbsp;that is, an array of Unicode characters (of possibly varying byte lengths). Since this regular expression is defined by a string pattern, it can only be used to search a string&nbsp;&mdash;&nbsp;again, an array of characters. But what we&#8217;re searching is not a string, it&#8217;s a byte array. Looking at the traceback, this error occurred in <code>universaldetector.py</code>:
ja:<p>Python 2では、文字列はバイトの配列であり、文字コードはそれとは別に追跡されていた。Python 2に文字コードを追跡させたいときは、代わりにUnicode文字列 (<code>u''</code>) を使わなければいけなかった。しかしPython 3では、文字列は常にPython 2がUnicode文字列と呼んでいたものだ。つまり、（おそらく可変バイト長の）Unicode文字の配列だ。この正規表現は文字列のパターンで定義されているので、これは文字列の検索だけに使用できる。しかし私たちが検索しているのは文字列ではなく、バイト列だ。トレースバックを見ると、このエラーは<code>universaldetector.py</code>で発生していることが分かる：


en:<p>And what is <var>aBuf</var>? Let&#8217;s backtrack further to a place that calls <code>UniversalDetector.feed()</code>. One place that calls it is the test harness, <code>test.py</code>.
ja:<p><var>aBuf</var>というのは何だろう？ <code>UniversalDetector.feed()</code>を呼び出しているところまでバックトラックしてみよう。これを呼び出している場所の1つは自動テストスクリプトの<code>test.py</code>だ。


en:<aside>Not an array of characters, but an array of bytes.</aside>
ja:<aside>文字の配列ではなく、バイトの配列。</aside>


en:<p>And here we find our answer: in the <code>UniversalDetector.feed()</code> method, <var>aBuf</var> is a line read from a file on disk. Look carefully at the parameters used to open the file: <code>'rb'</code>. <code>'r'</code> is for &#8220;read&#8221;; OK, big deal, we&#8217;re reading the file. Ah, but <a href=files.html#binary><code>'b'</code> is for &#8220;binary.&#8221;</a> Without the <code>'b'</code> flag, this <code>for</code> loop would read the file, line by line, and convert each line into a string&nbsp;&mdash;&nbsp;an array of Unicode characters&nbsp;&mdash;&nbsp;according to the system default character encoding. But with the <code>'b'</code> flag, this <code>for</code> loop reads the file, line by line, and stores each line exactly as it appears in the file, as an array of bytes. That byte array gets passed to <code>UniversalDetector.feed()</code>, and eventually gets passed to the pre-compiled regular expression, <var>self._highBitDetector</var>, to search for high-bit&hellip; characters. But we don&#8217;t have characters; we have bytes. Oops.
ja:<p>ここで答えを見つけた。<code>UniversalDetector.feed()</code>メソッドでは、<var>aBuf</var>はディスクから読み込んだファイルの1つの行だ。ファイルを開くときのパラメータを注意深く見てほしい: <code>'rb'</code>だ。<code>'r'</code>は「読み込み」を表す。オーケー、ここではファイルを読み込もうとしているわけだ。あっ、でも<a href=files.html#binary><code>'b'</code>は「バイナリ」を表すものだ</a>。もし<code>'b'</code>フラグが無かったら、この<code>for</code>ループはファイルを1行ずつ読み込んで、各々の行をシステムのデフォルト文字コードに従って文字列（Unicode文字の配列）に変換することになる。しかし、<code>'b'</code>フラグがあるときは、この<code>for</code>ループはファイルを1行ずつ読み込んで、各々の行を、ファイルに現れる通りにバイトの配列として格納する。そのバイト列は<code>UniversalDetector.feed()</code>に渡され、最終的には0x80-0xFFの「文字」を探すためのプリコンパイルされた正規表現<var>self._highBitDetector</var>に渡される。しかし、渡されたのは文字ではなく、バイトだ。これではダメだ。


en:<p>What we need this regular expression to search is not an array of characters, but an array of bytes.
ja:<p>私たちがこの正規表現に検索させたいのは文字の配列ではなく、バイトの配列だ。


en:<p>Once you realize that, the solution is not difficult. Regular expressions defined with strings can search strings. Regular expressions defined with byte arrays can search byte arrays. To define a byte array pattern, we simply change the type of the argument we use to define the regular expression to a byte array. (There is one other case of this same problem, on the very next line.)
ja:<p>これに気がつきさえすれば、解決方法は難しくない。文字列を使って定義した正規表現は文字列を検索できる。バイト列を使って定義した正規表現はバイト列を検索できる。バイト列のパターンを定義するには、正規表現を定義するのに使う引数の型をバイト列に変更するだけでいい（同じ問題がすぐ下の行にもある）。


en:<p>Searching the entire codebase for other uses of the <code>re</code> module turns up two more instances, in <code>charsetprober.py</code>. Again, the code is defining regular expressions as strings but executing them on <var>aBuf</var>, which is a byte array. The solution is the same: define the regular expression patterns as byte arrays.
ja:<p>他に<code>re</code>モジュールを使っている部分が無いかコードベース全体を検索してみると、<code>charsetprober.py</code>の中に2ヶ所あることが分かった。ここでもまた、文字列の正規表現を定義しながら、それをバイト列である<var>aBuf</var>に対して実行している。解決方法は同じだ。正規表現パターンをバイト列として定義すればいい。


en:<h3 id=cantconvertbytesobject>Can't convert <code>'bytes'</code> object to <code>str</code> implicitly</h3>
ja:<h3 id=cantconvertbytesobject>Can't convert <code>'bytes'</code> object to <code>str</code> implicitly</h3>


en:<p>Curiouser and curiouser&hellip;
ja:<p>ますます奇妙だ&hellip;&hellip;


en:<p>There&#8217;s an unfortunate clash of coding style and Python interpreter here. The <code>TypeError</code> could be anywhere on that line, but the traceback doesn&#8217;t tell you exactly where it is. It could be in the first conditional or the second, and the traceback would look the same. To narrow it down, you should split the line in half, like this:
ja:<p>ここにはコーディングスタイルとPythonインタプリタの不幸な衝突がある。<code>TypeError</code>はこの行のどの部分にでも起こりうるのだが、トレースバックはその正確な場所を教えてはくれない。例外が発生しているのは1つ目の条件文かもしれないし、2つ目の条件文かもしれないのだが、どちらにしても同じトレースバックが出力される。原因を絞り込むために、この行を次のように途中で分けるのがよいだろう：


en:<p>And re-run the test:
ja:<p>そして、テストを再実行する：


en:<p>Aha! The problem was not in the first conditional (<code>self._mInputState == ePureAscii</code>) but in the second one. So what could cause a <code>TypeError</code> there? Perhaps you&#8217;re thinking that the <code>search()</code> method is expecting a value of a different type, but that wouldn&#8217;t generate this traceback. Python functions can take any value; if you pass the right number of arguments, the function will execute. It may <em>crash</em> if you pass it a value of a different type than it&#8217;s expecting, but if that happened, the traceback would point to somewhere inside the function. But this traceback says it never got as far as calling the <code>search()</code> method. So the problem must be in that <code>+</code> operation, as it&#8217;s trying to construct the value that it will eventually pass to the <code>search()</code> method.
ja:<p>なるほど！ 問題は1つ目の条件 (<code>self._mInputState == ePureAscii</code>) ではなく、2つ目の条件にあったのだ。だとすると、何が<code>TypeError</code>を引きおこしたのだろうか？ ここで、想定していない型の値を<code>search()</code>メソッドに渡したからだ、と考えた人もいるかもしれない。しかし、それだとこのトレースバックは出てこない。Pythonの関数はどんな値でも引数に取れるので、正しい個数の引数を渡しさえすれば、その関数は実行される。想定していない型の値を渡したら関数はクラッシュするかもしれないが、そうなったとしても、エラーが発生した場所としてトレースバックが指し示すのはその関数の内部のどこかだ。このトレースバックは、<code>search()</code>メソッドを実行するところまで処理が進まなかったことを示している。従って、問題はこの<code>+</code>演算子の部分にあることになる。ここで<code>search()</code>メソッドに渡す値を構築するときにエラーが起きたのだ。


en:<p>We know from <a href=#cantuseastringpattern>previous debugging</a> that <var>aBuf</var> is a byte array. So what is <code>self._mLastChar</code>? It&#8217;s an instance variable, defined in the <code>reset()</code> method, which is actually called from the <code>__init__()</code> method.
ja:<p>私たちは<a href=#cantuseastringpattern>以前のデバッグ作業</a>から、<var>aBuf</var>がバイト列であることを知っている。では、<code>self._mLastChar</code>は何だろう？ これは<code>reset()</code>メソッドで定義されているインスタンス変数だ。このメソッドは実のところ<code>__init__()</code>メソッドから呼び出されている。


en:<p>And now we have our answer. Do you see it? <var>self._mLastChar</var> is a string, but <var>aBuf</var> is a byte array. And you can&#8217;t concatenate a string to a byte array&nbsp;&mdash;&nbsp;not even a zero-length string.
ja:<p>もう答えは私たちの手の中にある。お分かりだろうか？ <var>self._mLastChar</var>は文字列であるが、<var>aBuf</var>はバイト列だ。そして文字列をバイト列と連結することはできない&nbsp;&mdash;&nbsp;たとえそれが長さ0の文字列であったとしてもだ。


en:<p>So what is <var>self._mLastChar</var> anyway? In the <code>feed()</code> method, just a few lines down from where the trackback occurred.
ja:<p>それで<var>self._mLastChar</var>は一体何なのか？ <code>feed()</code>メソッドの、トレースバックが起きた場所から数行下だ。


en:<p>The calling function calls this <code>feed()</code> method over and over again with a few bytes at a time. The method processes the bytes it was given (passed in as <var>aBuf</var>), then stores the last byte in <var>self._mLastChar</var> in case it&#8217;s needed during the next call. (In a multi-byte encoding, the <code>feed()</code> method might get called with half of a character, then called again with the other half.)  But because <var>aBuf</var> is now a byte array instead of a string, <var>self._mLastChar</var> needs to be a byte array as well. Thus:
ja:<p>呼び出し元の関数は、一度に数バイトずつ渡しながら<code>feed()</code>メソッドを何度も呼び出す。このメソッドは与えられたバイト（<var>aBuf</var>として渡される）を処理し、次回の呼び出しで必要になったときのために最後のバイトを<var>self._mLastChar</var>に保存しておく（マルチバイトのエンコーディングでは、最初に一文字を構成するバイト列の半分だけが<code>feed()</code>メソッドに渡され、後でもう半分が渡されるということがあるからだ）。しかし、<var>aBuf</var>は今は文字列ではなくバイト列なので、<var>self._mLastChar</var>も同様にバイト列である必要がある。したがって：


en:<p>Searching the entire codebase for &#8220;<code>mLastChar</code>&#8221; turns up a similar problem in <code>mbcharsetprober.py</code>, but instead of tracking the last character, it tracks the last <em>two</em> characters. The <code>MultiByteCharSetProber</code> class uses a list of 1-character strings to track the last two characters. In Python 3, it needs to use a list of integers, because it&#8217;s not really tracking characters, it&#8217;s tracking bytes. (Bytes are just integers from <code>0-255</code>.)
ja:<p>コードベース全体から&#8220;<code>mLastChar</code>&#8221;を検索すると、似たような問題が<code>mbcharsetprober.py</code>に現れるが、ここでは最後の文字だけではなく、最後の<em>2文字</em>を追跡している。そして、この<code>MultiByteCharSetProber</code>クラスは最後の2文字を1文字ごとに分けてリストとして保存している。Python 3では、これは実際には文字を追跡するのではなくバイトを追跡しているので、整数のリストを使う必要がある（バイトは単なる<code>0-255</code>の整数だ）。


en:<h3 id=unsupportedoperandtypeforplus>Unsupported operand type(s) for +: <code>'int'</code> and <code>'bytes'</code></h3>
ja:<h3 id=unsupportedoperandtypeforplus>Unsupported operand type(s) for +: <code>'int'</code> and <code>'bytes'</code></h3>


en:<p>I have good news, and I have bad news. The good news is we&#8217;re making progress&hellip;
ja:<p>良い知らせと悪い知らせがある。良い知らせは、着実に作業は進んでいるということであり&hellip;&hellip;


en:<p>&hellip;The bad news is it doesn&#8217;t always feel like progress.
ja:<p>&hellip;&hellip;悪い知らせは、これがちっとも進んでいるとは感じられないことだ。


en:<p>But this is progress! Really! Even though the traceback calls out the same line of code, it&#8217;s a different error than it used to be. Progress! So what&#8217;s the problem now? The last time I checked, this line of code didn&#8217;t try to concatenate an <code>int</code> with a byte array (<code>bytes</code>). In fact, you just spent a lot of time <a href=#cantconvertbytesobject>ensuring that <var>self._mLastChar</var> was a byte array</a>. How did it turn into an <code>int</code>?
ja:<p>しかし、ちゃんと前に進んでいるのだ！ 本当だよ！ トレースバックは同じコード行を指し示しているけれども、これは前のエラーとは違うものだ。だから一歩前進だ！ それで、今度の問題は何なのだろうか？ さっき見たときは、このコードは<code>int</code>とバイト列 (<code>bytes</code>) を連結させるなんてことはしていなかった。実際、つい先ほど多くの時間を費やして<a href=#cantconvertbytesobject><var>self._mLastChar</var>がバイト列になるように修正した</a>ばかりだ。それがなぜ<code>int</code>になってしまったのだろうか？


en:<p>The answer lies not in the previous lines of code, but in the following lines.
ja:<p>答えはコードの前方の行ではなく、後方の行にある。


en:<aside>Each item in a string is a string. Each item in a byte array is an integer.</aside>
ja:<aside>文字列の各要素は文字列だ。バイト列の各要素は整数だ。</aside>


en:<p>This error doesn&#8217;t occur the first time the <code>feed()</code> method gets called; it occurs the <em>second time</em>, after <var>self._mLastChar</var> has been set to the last byte of <var>aBuf</var>. Well, what&#8217;s the problem with that? Getting a single element from a byte array yields an integer, not a byte array. To see the difference, follow me to the interactive shell:
ja:<p>このエラーは初めて<code>feed()</code>メソッドが呼び出されたときには発生しない。エラーは、<var>aBuf</var>の最後のバイトが<var>self._mLastChar</var>に代入されたあとの<em>2回目</em>の呼び出しで発生するのだ。そこにどんな問題があるのだろう？ 実は、バイト列から要素を一つだけ取り出すと、バイト列ではなく整数が得られるのだ。その違いを見るために、対話シェルで私についてきてほしい。


en:<li>Define a byte array of length 3.
ja:<li>長さ3のバイト列を定義する。


en:<li>The last element of the byte array is 191.
ja:<li>バイト列の最後の要素は191だ。


en:<li>That&#8217;s an integer.
ja:<li>これは整数だ。


en:<li>Concatenating an integer with a byte array doesn&#8217;t work. You&#8217;ve now replicated the error you just found in <code>universaldetector.py</code>.
ja:<li>整数とバイト列の連結は機能しない。今あなたは、<code>universaldetector.py</code>で見つけたエラーを再現したのだ。


en:<li>Ah, here&#8217;s the fix. Instead of taking the last element of the byte array, use <a href=native-datatypes.html#slicinglists>list slicing</a> to create a new byte array containing just the last element. That is, start with the last element and continue the slice until the end of the byte array. Now <var>mLastChar</var> is a byte array of length 1.
ja:<li>これがバグを修正する方法だ。つまり、バイト列の最後の要素を取る代わりに、<a href=native-datatypes.html#slicinglists>リストのスライス</a>を使って最後の要素だけからなる新しいバイト列を作成するのだ。そのためには、最後の要素から始めてバイト列の終わりまでを切り出せばいい。これで<var>mLastChar</var>は長さ1のバイト列になった。


en:<li>Concatenating a byte array of length 1 with a byte array of length 3 returns a new byte array of length 4.
ja:<li>長さ1のバイト列と長さ3のバイト列を連結させれば、長さ4の新しいバイト列が返される。


en:<p>So, to ensure that the <code>feed()</code> method in <code>universaldetector.py</code> continues to work no matter how often it&#8217;s called, you need to <a href=#cantconvertbytesobject>initialize <var>self._mLastChar</var> as a 0-length byte array</a>, then <em>make sure it stays a byte array</em>.
ja:<p><code>universaldetector.py</code>の<code>feed()</code>メソッドが呼び出される回数に関わり無く、ちゃんと実行されるようにするためには、<a href=#cantconvertbytesobject><var>self._mLastChar</var>の初期値を長さ0のバイト列に設定しておいて</a>、<em>この値がバイト列のまま保たれるようにする必要があるのだ</em>。


en:<h3 id=ordexpectedstring><code>ord()</code> expected string of length 1, but <code>int</code> found</h3>
ja:<h3 id=ordexpectedstring><code>ord()</code> expected string of length 1, but <code>int</code> found</h3>


en:<p>Tired yet? You&#8217;re almost there&hellip;
ja:<p>もう疲れてしまったかな？ ゴールはもうすぐだ&hellip;&hellip;


en:<p>OK, so <var>c</var> is an <code>int</code>, but the <code>ord()</code> function was expecting a 1-character string. Fair enough. Where is <var>c</var> defined?
ja:<p>オーケー、つまり<var>c</var>は<code>int</code>型だけど、<code>ord()</code>関数は1文字の文字列しか受け取れないというわけだ。ごもっとも。<var>c</var>はどこで定義されているのだろうか？


en:<p>That&#8217;s no help; it&#8217;s just passed into the function. Let&#8217;s pop the stack.
ja:<p>ここからは何も分からない。<var>c</var>は関数に渡されているだけだ。呼び出しスタックをさかのぼろう。


en:<p>Do you see it? In Python 2, <var>aBuf</var> was a string, so <var>c</var> was a 1-character string. (That&#8217;s what you get when you iterate over a string&nbsp;&mdash;&nbsp;all the characters, one by one.) But now, <var>aBuf</var> is a byte array, so <var>c</var> is an <code>int</code>, not a 1-character string. In other words, there&#8217;s no need to call the <code>ord()</code> function because <var>c</var> is already an <code>int</code>!
ja:<p>分かったかな？ Python 2では、<var>aBuf</var>は文字列だったので、<var>c</var>は1文字の文字列だった（文字列をイテレートすると文字が一つずつ取り出されるからだ）。しかし、ここでは<var>aBuf</var>はバイト列になっているので、<var>c</var>は1文字の文字列ではなく<code>int</code>だ。言い換えると、<var>c</var>はすでに<code>int</code>なので、<code>ord()</code>関数を呼び出す必要はないということだ！


en:<p>Thus:
ja:<p>したがってこうすればいい：


en:<p>Searching the entire codebase for instances of &#8220;<code>ord(c)</code>&#8221; uncovers similar problems in <code>sbcharsetprober.py</code>&hellip;
ja:<p>コードベース全体から &#8220;<code>ord(c)</code>&#8221; を検索すると、同様の問題が<code>sbcharsetprober.py</code>にもあることが明らかとなる&hellip;&hellip;


en:<p>&hellip;and <code>latin1prober.py</code>&hellip;
ja:<p>&hellip;&hellip;そして<code>latin1prober.py</code>にも&hellip;&hellip;


en:<p><var>c</var> is iterating over <var>aBuf</var>, which means it is an integer, not a 1-character string.  The solution is the same: change <code>ord(c)</code> to just plain <code>c</code>.
ja:<p>ここでは<var>aBuf</var>をイテレートしているので、<var>c</var>は1文字の文字列ではなく整数になることがわかる。解決方法は同じだ。<code>ord(c)</code>を単なる<code>c</code>に変更すればいい。


en:<h3 id=unorderabletypes>Unorderable types: <code>int()</code> >= <code>str()</code></h3>
ja:<h3 id=unorderabletypes>Unorderable types: <code>int()</code> >= <code>str()</code></h3>


en:<p>Let&#8217;s go again.
ja:<p>またテストしよう。


en:<p>So what&#8217;s this all about? &#8220;Unorderable types&#8221;? Once again, the difference between byte arrays and strings is rearing its ugly head. Take a look at the code:
ja:<p>一体全体どういうことだ？ 「Unorderable types（順序付けできない型）」とは何だ？ これは、バイト列と文字列の違いがまたまた姿を現したのだ。コードを見てみよう：


en:<p>And where does <var>aStr</var> come from? Let&#8217;s pop the stack:
ja:<p><var>aStr</var>はどこから来たのだろう？ 呼び出しスタックをさかのぼろう：


en:<p>Oh look, it&#8217;s our old friend, <var>aBuf</var>. As you might have guessed from every other issue we&#8217;ve encountered in this chapter, <var>aBuf</var> is a byte array. Here, the <code>feed()</code> method isn&#8217;t just passing it on wholesale; it&#8217;s slicing it. But as you saw <a href=#unsupportedoperandtypeforplus>earlier in this chapter</a>, slicing a byte array returns a byte array, so the <var>aStr</var> parameter that gets passed to the <code>get_order()</code> method is still a byte array.
ja:<p>おや、これは昔なじみの<var>aBuf</var>ではないか。この章で出くわした他の問題から察しが付いていると思うが、<var>aBuf</var>はバイト列だ。ここで<code>feed()</code>メソッドは、<var>aBuf</var>をそのまま渡しているわけではなく、これをスライスしている。しかし、<a href=#unsupportedoperandtypeforplus>この章の前の方</a>で見たように、バイト列のスライスはバイト列を返すので、<code>get_order()</code>メソッドに渡される<var>aStr</var>パラメータは依然としてバイト列だ。


en:<p>And what is this code trying to do with <var>aStr</var>? It&#8217;s taking the first element of the byte array and comparing it to a string of length 1. In Python 2, that worked, because <var>aStr</var> and <var>aBuf</var> were strings, and <var>aStr[0]</var> would be a string, and you can compare strings for inequality. But in Python 3, <var>aStr</var> and <var>aBuf</var> are byte arrays, <var>aStr[0]</var> is an integer, and you can&#8217;t compare integers and strings for inequality without explicitly coercing one of them.
ja:<p>このコードは<var>aStr</var>を使って何をしようとしているのだろうか？ これは、バイト列の最初の要素を受け取って、それを長さ1の文字列と比較しているのだ。Python 2ではこれは動作する。なぜなら<var>aStr</var>と<var>aBuf</var>はどちらも文字列なので<var>aStr[0]</var>も文字列となり、文字列同士は不等式で比較することができるからだ。しかしPython 3では、<var>aStr</var>と<var>aBuf</var>はバイト列であり、<var>aStr[0]</var>は整数なので、どちらかを明示的に型強制しない限り、整数と文字列を不等式で比較することはできない。


en:<p>In this case, there&#8217;s no need to make the code more complicated by adding an explicit coercion. <var>aStr[0]</var> yields an integer; the things you&#8217;re comparing to are all constants. Let&#8217;s change them from 1-character strings to integers. And while we&#8217;re at it, let&#8217;s change <var>aStr</var> to <var>aBuf</var>, since it&#8217;s not actually a string.
ja:<p>この場合には、明示的な型強制を加えてコードをより複雑にする必要はない。<var>aStr[0]</var>は整数であり、ここで比較の対象になっているのはすべて定数だ。この比較のための定数を1文字の文字列から整数に変更することにしよう。そのついでに、<var>aStr</var>を<var>aBuf</var>に変更しよう。これは実際には文字列ではないからね。


en:<p>Searching the entire codebase for occurrences of the <code>ord()</code> function uncovers the same problem in <code>chardistribution.py</code> (specifically, in the <code>EUCTWDistributionAnalysis</code>, <code>EUCKRDistributionAnalysis</code>, <code>GB2312DistributionAnalysis</code>, <code>Big5DistributionAnalysis</code>, <code>SJISDistributionAnalysis</code>, and <code>EUCJPDistributionAnalysis</code> classes. In each case, the fix is similar to the change we made to the <code>EUCJPContextAnalysis</code> and <code>SJISContextAnalysis</code> classes in <code>jpcntx.py</code>.
ja:<p>コードベースから<code>ord()</code>関数が使われている部分を探すと、同じ問題が<code>chardistribution.py</code>にもあることが分かる（具体的には<code>EUCTWDistributionAnalysis</code>、<code>EUCKRDistributionAnalysis</code>、<code>GB2312DistributionAnalysis</code>、<code>Big5DistributionAnalysis</code>、<code>SJISDistributionAnalysis</code>、<code>EUCJPDistributionAnalysis</code>クラスの中）。ここでは、それぞれのクラスについて先ほど<code>jpcntx.py</code>の<code>EUCJPContextAnalysis</code>と<code>SJISContextAnalysis</code>クラスに加えたものと同じ修正を施せばいい。


en:<h3 id=reduceisnotdefined>Global name <code>'reduce'</code> is not defined</h3>
ja:<h3 id=reduceisnotdefined>Global name <code>'reduce'</code> is not defined</h3>


en:<p>Once more into the breach&hellip;
ja:<p>突破まであと一つ&hellip;&hellip;


en:<p>According to the official <a href=http://docs.python.org/3.0/whatsnew/3.0.html#builtins>What&#8217;s New In Python 3.0</a> guide, the <code>reduce()</code> function has been moved out of the global namespace and into the <code>functools</code> module. Quoting the guide: &#8220;Use <code>functools.reduce()</code> if you really need it; however, 99 percent of the time an explicit <code>for</code> loop is more readable.&#8221; You can read more about the decision from Guido van Rossum&#8217;s weblog: <a href='http://www.artima.com/weblogs/viewpost.jsp?thread=98196'>The fate of reduce() in Python 3000</a>.
ja:<p>公式の<a href=http://docs.python.org/3.0/whatsnew/3.0.html#builtins>What&#8217;s New In Python 3.0</a>ガイドによると、<code>reduce()</code>関数はグローバル名前空間から<code>functools</code>モジュールに移されている。さらに、ガイドはこの関数について「本当に必要なのであれば<code>functools.reduce()</code>を使ってほしい。だが、99%の状況においては率直な<code>for</code>ループの方が読みやすい」としている。この決定の詳細は、Guido van Rossumのブログ記事 <a href='http://www.artima.com/weblogs/viewpost.jsp?thread=98196'>The fate of reduce() in Python 3000</a> で読める。


en:<p>The <code>reduce()</code> function takes two arguments&nbsp;&mdash;&nbsp;a function and a list (strictly speaking, any iterable object will do)&nbsp;&mdash;&nbsp;and applies the function cumulatively to each item of the list. In other words, this is a fancy and roundabout way of adding up all the items in a list and returning the result.
ja:<p><code>reduce()</code>関数は2つの引数&nbsp;&mdash;&nbsp;関数とリスト（厳密に言うとイテレート可能なオブジェクトなら何でもいい）&nbsp;&mdash;&nbsp;を受け取り、その関数をリストの各々の要素に累積的に適用する。言い換えると、これはリストの要素を足し合わせた結果を返すための派手で遠回しな方法だ。


en:<p>This monstrosity was so common that Python added a global <code>sum()</code> function.
ja:<p>この奇怪な手法はとても一般的だったので、Pythonは<code>sum()</code>というグローバル関数を追加している。


en:<p>Since you&#8217;re no longer using the <code>operator</code> module, you can remove that <code>import</code> from the top of the file as well.
ja:<p><code>operator</code>モジュールはもう使われていないので、ファイルの先頭にある<code>import</code>は除去できる。


en:<p>I CAN HAZ TESTZ?
ja:<p>テストは通るかなー？


en:<p>Holy crap, it actually works! <em><a href=http://www.hampsterdance.com/>/me does a little dance</a></em>
ja:<p>やったー、確かにちゃんと動いてる！ <em><a href=http://www.hampsterdance.com/>/me does a little dance</a></em>


en:<h2 id=summary>Summary</h2>
ja:<h2 id=summary>まとめ</h2>


en:<p>What have we learned?
ja:<p>私たちは何を学んだのだろうか？


en:<li>Porting any non-trivial amount of code from Python 2 to Python 3 is going to be a pain. There&#8217;s no way around it. It&#8217;s hard.
ja:<li>どんなコードであっても、少なからぬ量のコードをPython 2からPython 3へ移植する作業は苦しいものになる。これを避けて通る道は存在しない。この作業は骨の折れるものなのだ。


en:<li>The <a href=porting-code-to-python-3-with-2to3.html>automated <code>2to3</code> tool</a> is helpful as far as it goes, but it will only do the easy parts&nbsp;&mdash;&nbsp;function renames, module renames, syntax changes. It&#8217;s an impressive piece of engineering, but in the end it&#8217;s just an intelligent search-and-replace bot.
ja:<li><a href=porting-code-to-python-3-with-2to3.html>自動化された<code>2to3</code>ツール</a>はある程度は役に立つが、これは簡単な部分（関数名の変更、モジュール名の変更、構文の変更）しかやってくれない。このツールは見事な技術で作られたものではあるが、結局のところ、検索と置換を行う賢いロボット以上のものではない。


en:<li>The #1 porting problem in this library was the difference between strings and bytes. In this case that seems obvious, since the whole point of the <code>chardet</code> library is to convert a stream of bytes into a string. But &#8220;a stream of bytes&#8221; comes up more often than you might think. Reading a file in &#8220;binary&#8221; mode? You&#8217;ll get a stream of bytes. Fetching a web page? Calling a web <abbr>API</abbr>? They return a stream of bytes, too.
ja:<li>このライブラリを移植する上で最大の障害となったのは、文字列とバイト列の違いだった。これが最大の障害になるのは当然だと思うかもしれない。そもそも、<code>chardet</code>モジュールはバイトのストリームを文字に変換するためのプログラムだからだ。しかし、「バイトのストリーム」というものは思いのほか色々なところに現れるものだ。ファイルを「バイナリ」モードで読み込むって？ それで手に入るのはバイトのストリームだ。ウェブページを取得する？ ウェブ上の<abbr>API</abbr>を呼び出す？ これはどれもバイトのストリームを返すのだ。


en:<li><em>You</em> need to understand your program. Thoroughly. Preferably because you wrote it, but at the very least, you need to be comfortable with all its quirks and musty corners. The bugs are everywhere.
ja:<li><em>あなた</em>は自分のプログラムを理解する必要がある。それも完璧に。できれば、自分で書いたプログラムであることが望ましいのだが、そうでなくとも、そのプログラムの奇妙な点や汚い部分に親しみを感じるくらいにならなければならない。バグはそこら中にあるのだ。


en:<li>Test cases are essential. Don&#8217;t port anything without them. The <em>only</em> reason I have any confidence that <code>chardet</code> works in Python 3 is that I started with a test suite that exercised all major code paths. If you don&#8217;t have any tests, write some tests before you start porting to Python 3. If you have a few tests, write more. If you have a lot of tests, then the real fun can begin.
ja:<li>テストケースは絶対に必要だ。テストケースなしに移植を行ってはいけない。私が<code>chardet</code>がPython 3で動作することに自信を持っている<em>唯一</em>の理由は、私がすべての主要なコードパスを網羅するテストスイートを作ることから始めたからだ。もしテストを一切持っていないのであれば、Python 3への移植を始める前にいくらかのテストを書こう。テストを少し持っているのであれば、もっとたくさん書こう。たくさんのテストを持っているのであれば、本当に楽しいことが始められる。


en:<p class=v><a rel=prev href=http-web-services.html title='back to &#8220;HTTP Web Services&#8221;'><span class=u>&#x261C;</span></a> <a rel=next href=packaging.html title='onward to &#8220;Packaging Python Libraries&#8221;'><span class=u>&#x261E;</span></a>
ja:<p class=v><a rel=prev href=http-web-services.html title='「HTTPウェブサービス」へ戻る'><span class=u>&#x261C;</span></a> <a rel=next href=packaging.html title='「Pythonライブラリをパッケージ化する」へ進む'><span class=u>&#x261E;</span></a>

